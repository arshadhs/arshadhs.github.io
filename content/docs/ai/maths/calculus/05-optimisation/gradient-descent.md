---
title: "Optimisation using Gradient Descent"
draft: false
tags: ["Machine Learning", "Mathematics", "Linear Algebra"]
categories: ["AI", "ML"]
weight: 1510
---
# Optimisation using Gradient Descent

Gradient descent is an optimisation algorithm used to train ML and neural networks.

- Gradient descent updates parameters by moving opposite the gradient.

Trains ML models by minimising errors:
- between predicted and actual results
- by iteratively adjusting its parameters
- moves step‑by‑step in the direction of the steepest decrease in the loss function, it helps ML models learn the best possible weights for better predictions

---

## Types of Gradient Gescent learning algorithms

1. Batch gradient descent
2. Stochastic gradient descent
3. Mini-batch gradient descent

---

{{< home-link "Home" >}} | {{< section-index >}}
