---
title: 'Attention Mechanism'
draft: false
tags: ["AI", "ML", "Neural Networks"]
categories: ["AI", "ML"]
weight: 1100
menu: main
---

# Attention Mechanism

- Attention Pooling
- Attention Scoring Functions
- Multi-Head Attention, Self-Attention and Positional Encoding

- Transformer architecture
- Applications of Transformers

---
  
## Reference
- **Dive into deep learning. Cambridge University Press.**. ([Ch 10](https://d2l.ai/chapter_builders-guide/model-construction.html), [Ch7](https://d2l.ai/chapter_convolutional-neural-networks/index.html)

---

{{< home-link "Home" >}} | {{< section-index >}}
